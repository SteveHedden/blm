{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import community\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and Clean Raw Json File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"/Users/StephenHedden/Downloads/40400-tweets.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScreenName(x):\n",
    "    try:\n",
    "        temp = x[\"screen_name\"]\n",
    "        return temp;\n",
    "    except:\n",
    "        return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOrigScreenName(x):\n",
    "    try:\n",
    "        temp = x[\"user\"][\"screen_name\"]\n",
    "        return temp;\n",
    "    except:\n",
    "        return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMentions(x):\n",
    "    try:\n",
    "        temp = x[\"user_mentions\"][0][\"screen_name\"]\n",
    "        return temp;\n",
    "    except:\n",
    "        return np.NaN;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a source column in the df for the sn of the tweeter\n",
    "df['source'] = df[\"user\"].apply(lambda x: getScreenName(x))\n",
    "df['target'] = df['retweeted_status'].apply(lambda x: getOrigScreenName(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges1 = pd.DataFrame() #Create empty df\n",
    "\n",
    "#Break into retweets and non-reweets\n",
    "rts = df.loc[~pd.isnull(df[\"retweeted_status\"])]\n",
    "nonrts = df.loc[pd.isnull(df[\"retweeted_status\"])]\n",
    "\n",
    "#Create edges for rts\n",
    "edges1['source'] = rts[\"user\"].apply(lambda x: getScreenName(x))\n",
    "edges1['target'] = rts['retweeted_status'].apply(lambda x: getOrigScreenName(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create edges for mentions\n",
    "edges2 = pd.DataFrame()\n",
    "edges2['source'] = nonrts[\"user\"].apply(lambda x: getScreenName(x))\n",
    "edges2['target'] = nonrts['entities'].apply(lambda x: getMentions(x))\n",
    "edges2 = edges2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = pd.concat([edges1,edges2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ExpatPip</td>\n",
       "      <td>JuliaHB1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>debysoto21</td>\n",
       "      <td>JByazminn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_niverse</td>\n",
       "      <td>Variety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Merwyn65</td>\n",
       "      <td>akshaykumar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marijara1971</td>\n",
       "      <td>MariaFdaCabal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         source         target\n",
       "0      ExpatPip       JuliaHB1\n",
       "1    debysoto21      JByazminn\n",
       "2     v_niverse        Variety\n",
       "3      Merwyn65    akshaykumar\n",
       "4  marijara1971  MariaFdaCabal"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create graph and run centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create graph using the data\n",
    "G=nx.from_pandas_edgelist(edges, 'source', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Partition graph based on 'best partition'\n",
    "partition = community.best_partition(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn partition into dataframe\n",
    "partition1 = pd.DataFrame([partition]).T\n",
    "partition1 = partition1.reset_index()\n",
    "partition1.columns = ['index','value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Degree Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dc = nx.degree_centrality(G)\n",
    "dc = pd.DataFrame([dc.keys(), dc.values()]).T\n",
    "dc.columns= ['names', 'values']  # call them whatever you like\n",
    "dc = dc.sort_values(by='values', ascending=False)\n",
    "dc1 = pd.merge(dc,partition1, how='left', left_on=\"names\",right_on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Betweenness Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-07 18:44:37.727894\n",
      "2020-06-07 18:46:48.177185\n"
     ]
    }
   ],
   "source": [
    "print(datetime.datetime.now())\n",
    "bc = nx.betweenness_centrality(G,k=1000)\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = pd.DataFrame([bc.keys(), bc.values()]).T\n",
    "bc.columns= ['names', 'values']  # call them whatever you like\n",
    "bc = bc.sort_values(by='values', ascending=False)\n",
    "bc.to_csv(\"bc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc1 = pd.merge(bc,partition1, how='left', left_on=\"names\",right_on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eigenvector Centrality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec = nx.eigenvector_centrality(G,weight='freq',max_iter=1000)\n",
    "ec = pd.DataFrame([ec.keys(), ec.values()]).T\n",
    "ec.columns= ['names', 'values']\n",
    "ec = ec.sort_values(by='values', ascending=False)\n",
    "ec1 = pd.merge(ec,partition1, how='left', left_on=\"names\",right_on=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data for JS\n",
    "## Required Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createTopNodesforVisual(df,nameOfFile,head,threshold,minDegree):\n",
    "    #Only use groups with more than X members\n",
    "    top = df.groupby('value')['names'].filter(lambda x: len(x) > 0)\n",
    "    df = df.loc[df['names'].isin(top)]\n",
    "    degreeNetwork = filterByPartitionAndCentrality(df,head,threshold)\n",
    "    degreeNetwork = degreeNetwork.sort_values(by=\"values\",ascending=False).head(head)\n",
    "    singles = degreeNetwork.groupby('value')['names'].filter(lambda x: len(x) < minDegree)\n",
    "    degreeNetwork = degreeNetwork.loc[~degreeNetwork['names'].isin(singles)]\n",
    "    degreeNetwork = buildNetworkFromData(edges,degreeNetwork,minDegree)\n",
    "    nodes = buildNodesFromLinks(degreeNetwork,df)\n",
    "    #exportData(nodes,degreeNetwork,nameOfFile)\n",
    "    return(nodes,degreeNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterByPartitionAndCentrality(df,head,centralityThreshold):\n",
    "    df = df.groupby('value').head(head)\n",
    "    #df = df.head(head)\n",
    "    df = df.loc[df['values'] > centralityThreshold]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNetworkFromData(network, df, minDegree):\n",
    "    df = network.loc[(network['source'].isin(df['names'])) & (network['target'].isin(df['names']))]\n",
    "    G_clean = nx.from_pandas_edgelist(df, 'source', 'target')\n",
    "    remove = [node for node,degree in dict(G_clean.degree()).items() if degree < minDegree]\n",
    "    G_clean.remove_nodes_from(remove)\n",
    "    G_clean = nx.to_pandas_edgelist(G_clean)\n",
    "    #G_clean = pd.merge(G_clean,names,how='left',left_on='source',right_on='nconst')\n",
    "    #G_clean = pd.merge(G_clean,names,how='left',left_on='target',right_on='nconst')\n",
    "    G_clean = pd.DataFrame(G_clean[['source','target']])\n",
    "    #G_clean.columns = ['source','target']\n",
    "    #G_clean = G_clean.dropna()\n",
    "    #G_clean = G_clean.drop_duplicates()\n",
    "    return G_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNodesFromLinks(df,centralityData):\n",
    "    nodes1 = pd.DataFrame(df['source'])\n",
    "    nodes2 = pd.DataFrame(df['target'])\n",
    "    nodes2.columns = ['source']\n",
    "    nodes = pd.concat([nodes1,nodes2])\n",
    "    nodes = nodes.drop_duplicates()\n",
    "    nodes2 = pd.merge(nodes,centralityData,how='left',left_on='source',right_on='names')\n",
    "    nodes2 = nodes2.dropna()\n",
    "    nodes2 = pd.DataFrame(nodes2[['names','values','value']])\n",
    "    nodes2.columns = ['id','cent','value']\n",
    "    return nodes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportData(nodes,network,fileName):\n",
    "    d1 = nodes.to_dict(orient='records')\n",
    "    j1 = json.dumps(d1)\n",
    "    d2 = network.to_dict(orient='records')\n",
    "    j2 = json.dumps(d2)\n",
    "    d1 = {\"nodes\":d1, \"links\":d2}\n",
    "    with open(fileName + \".json\", 'w', encoding='utf-8') as f:\n",
    "        json.dump(d1, f, ensure_ascii=False,indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create nodes and nets (they will need to be modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inputs are nodes data to filter on, name of file to save it as, \n",
    "#number of maximum nodes to take from each community, minimum centrality score\n",
    "#and minimum numbe of connections\n",
    "nodes,net = createTopNodesforVisual(bc1,\"test\",10000,0.0001,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       1344\n",
       "cent     1344\n",
       "value    1344\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Make sure it's less than like 2000\n",
    "nodes.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make it exactly right for the d3 visual\n",
    "nodes = buildNodesFromLinks(net,bc1)\n",
    "nodes = nodes.rename(columns={\"cent\": \"betweenness\", \"value\": \"group\",\"id\":\"name\"})\n",
    "nodes = nodes.reset_index()\n",
    "nodes = nodes.rename(columns={\"index\": \"id\"})\n",
    "net[\"source\"] = net[\"source\"].apply(lambda x: nodes.loc[nodes[\"name\"] == x][\"id\"].values[0])\n",
    "net[\"target\"] = net[\"target\"].apply(lambda x: nodes.loc[nodes[\"name\"] == x][\"id\"].values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with other centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.merge(nodes,ec1, how=\"left\",left_on=\"name\",right_on=\"names\")\n",
    "nodes = nodes.drop(['names','index','value'], axis=1)\n",
    "nodes = nodes.rename(columns={\"values\": \"eigenvector\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = pd.merge(nodes,dc1, how=\"left\",left_on=\"name\",right_on=\"names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = nodes.drop(['names','index','value'], axis=1)\n",
    "nodes = nodes.rename(columns={\"values\": \"degree\"})\n",
    "nodes = nodes[['betweenness','degree','eigenvector','group','id','name']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add text to each node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText1(x,df):\n",
    "    length1 = len(df.loc[df[\"source\"] == x][\"text\"])\n",
    "    length2 = len(df.loc[df[\"target\"] == x][\"text\"])\n",
    "    if length1 > 0:\n",
    "        text = df.loc[df[\"source\"] == x][\"text\"].values[0]\n",
    "        return text;\n",
    "    elif length2 > 0:\n",
    "        text = df.loc[df[\"target\"] == x][\"text\"].values[0]\n",
    "        return text;\n",
    "    else:\n",
    "        return;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes[\"tweet_text\"] = nodes[\"name\"].apply(lambda x: getText1(x,df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>betweenness</th>\n",
       "      <th>degree</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>group</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000970877</td>\n",
       "      <td>0.000870249</td>\n",
       "      <td>0.00121886</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>yeeyeetweetweet</td>\n",
       "      <td>RT @mckenzieas93V2: Racists seeing            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00102053</td>\n",
       "      <td>0.000280725</td>\n",
       "      <td>4.32654e-05</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>mckenzieas93V2</td>\n",
       "      <td>RT @mckenzieas93V2: Racists seeing            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000395545</td>\n",
       "      <td>0.00011229</td>\n",
       "      <td>0.0200751</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>litolkth</td>\n",
       "      <td>RT @JupiterIsPlane1: me when I saw #whitelives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00896225</td>\n",
       "      <td>0.00589523</td>\n",
       "      <td>0.014601</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>JupiterIsPlane1</td>\n",
       "      <td>RT @JupiterIsPlane1: me when I saw #whitelives...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00105677</td>\n",
       "      <td>0.00033687</td>\n",
       "      <td>0.0213399</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>jaebumjeon</td>\n",
       "      <td>RT @eternal_jungkoo: Kpop stans ready to take ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   betweenness       degree  eigenvector  group  id             name  \\\n",
       "0  0.000970877  0.000870249   0.00121886      7   0  yeeyeetweetweet   \n",
       "1   0.00102053  0.000280725  4.32654e-05      7   1   mckenzieas93V2   \n",
       "2  0.000395545   0.00011229    0.0200751      7   2         litolkth   \n",
       "3   0.00896225   0.00589523     0.014601      7   3  JupiterIsPlane1   \n",
       "4   0.00105677   0.00033687    0.0213399      7   4       jaebumjeon   \n",
       "\n",
       "                                          tweet_text  \n",
       "0  RT @mckenzieas93V2: Racists seeing            ...  \n",
       "1  RT @mckenzieas93V2: Racists seeing            ...  \n",
       "2  RT @JupiterIsPlane1: me when I saw #whitelives...  \n",
       "3  RT @JupiterIsPlane1: me when I saw #whitelives...  \n",
       "4  RT @eternal_jungkoo: Kpop stans ready to take ...  "
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export data\n",
    "exportData(nodes,net,\"test6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
